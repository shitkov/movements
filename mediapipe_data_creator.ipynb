{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mediapipe_data_creator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kyjB73SYtuA",
        "outputId": "40d1377b-7e20-465f-c135-70f8ac56f3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCoey2hb48_",
        "outputId": "183eedaa-55b5-496d-a756-2459542f8d81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.10.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bxDh4FfPcCBE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_correct = '/content/drive/MyDrive/ml/correct100.mp4'\n",
        "path_back = '/content/drive/MyDrive/ml/curved_back100_2.mp4'\n",
        "path_dont_sit_down = '/content/drive/MyDrive/ml/dont_sit_down100.mp4'\n",
        "path_knees_fell = '/content/drive/MyDrive/ml/knees_fell.mp4'\n",
        "path_uneven = '/content/drive/MyDrive/ml/uneven100.mp4'"
      ],
      "metadata": {
        "id": "jQxgpdl8ZYo9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths_list = [path_correct, path_back, path_dont_sit_down, path_knees_fell, path_uneven]"
      ],
      "metadata": {
        "id": "5S8Vlrcaqn0m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points = [0, 11, 12, 23, 24, 25, 26, 27, 28]"
      ],
      "metadata": {
        "id": "nkFE06k_dtR3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_points(path, key_points):\n",
        "    vidcap = cv2.VideoCapture(path)\n",
        "    points_list = []\n",
        "    for _ in tqdm(range(int(cv2.VideoCapture(path).get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "    # for _ in tqdm(range(10)):\n",
        "        _, image = vidcap.read()\n",
        "        try:\n",
        "            with mp.solutions.pose.Pose(static_image_mode=False, min_detection_confidence=0.3, model_complexity=1) as pose:\n",
        "                results = pose.process(image)\n",
        "            points = []\n",
        "            for i, point in enumerate(results.pose_world_landmarks.landmark):\n",
        "                if i in key_points:\n",
        "                    points.append([point.x, point.y, point.z])\n",
        "            points_list.append(np.array(points).reshape(-1))\n",
        "        except:\n",
        "            points_list.append(np.zeros(len(key_points) * 3))\n",
        "    return np.array(points_list)"
      ],
      "metadata": {
        "id": "5IvC0Brpd7re"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths_list:\n",
        "    name = path.split('/')[-1][:-4]\n",
        "    points_list = get_points(path, key_points)\n",
        "    with open('/content/drive/MyDrive/ml/' + name + '.p', 'wb') as f:\n",
        "        pickle.dump(points_list, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMq_wYtjmisH",
        "outputId": "6ba0b014-05f3-4512-e78b-79f87da5936b"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7076/7076 [25:56<00:00,  4.55it/s]\n",
            "100%|██████████| 6931/6931 [24:57<00:00,  4.63it/s]\n",
            "100%|██████████| 5898/5898 [21:15<00:00,  4.62it/s]\n",
            "100%|██████████| 6962/6962 [24:32<00:00,  4.73it/s]\n",
            "100%|██████████| 7292/7292 [25:57<00:00,  4.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load model 4 squats"
      ],
      "metadata": {
        "id": "VC9mQnB3UZfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MT0_Cb3aT5ZP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimleNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimleNetwork,self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, hidden_dim * 2)\n",
        "        self.linear2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aJjCFGCmUp0j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 27\n",
        "hidden_dim = 200\n",
        "output_dim = 1"
      ],
      "metadata": {
        "id": "dEXBu1yTUZBf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimleNetwork(input_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "CwolpF4pUsfG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ml/model_mov_v0.pt'));"
      ],
      "metadata": {
        "id": "50jKrKOdUucT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get predicts"
      ],
      "metadata": {
        "id": "FBIoP0QgVDqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/ml/VID_20220822_162003_146.mp4'\n",
        "\n",
        "vidcap = cv2.VideoCapture(path)\n",
        "predicts = []\n",
        "for _ in tqdm(range(int(cv2.VideoCapture(path).get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "    _, image = vidcap.read()\n",
        "    try:\n",
        "        with mp.solutions.pose.Pose(static_image_mode=False, min_detection_confidence=0.3, model_complexity=1) as pose:\n",
        "            results = pose.process(image)\n",
        "        points = []\n",
        "        for i, point in enumerate(results.pose_world_landmarks.landmark):\n",
        "            if i in key_points:\n",
        "                points.append([point.x, point.y, point.z])\n",
        "        points = np.array(points).reshape(-1)\n",
        "        with torch.no_grad():\n",
        "            predict = torch.sigmoid(model(torch.FloatTensor(points))).cpu().detach().numpy()[0]\n",
        "        predicts.append(predict)\n",
        "    except:\n",
        "        predicts.append(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFof4PxUVCw7",
        "outputId": "d321c78b-bbed-48e2-d7b8-f44c49a57a1a"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1683/1683 [05:56<00:00,  4.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cleaner:\n",
        "\n",
        "\n",
        "    def __init__(self, wide=10, threshold=15):\n",
        "        self.wide = wide\n",
        "        self.threshold = threshold\n",
        "    \n",
        "\n",
        "    def clean(self, predicts):\n",
        "        predicts = self._reduse_unrecognized(predicts)\n",
        "        predicts = self._sliding_window(predicts)\n",
        "        predicts = self._hysteresis(predicts)\n",
        "        predicts = self._mount_filter(predicts)\n",
        "        return predicts\n",
        "\n",
        "\n",
        "    def _reduse_unrecognized(self, predicts):\n",
        "        predicts_rep = []\n",
        "        for predict in predicts:\n",
        "            if predict == -1:\n",
        "                try:\n",
        "                    predicts_rep.append(predicts_rep[-1])\n",
        "                except:\n",
        "                    predicts_rep.append(predict)\n",
        "            else:\n",
        "                predicts_rep.append(predict)\n",
        "        return predicts_rep\n",
        "\n",
        "\n",
        "    def _sliding_window(self, predicts):\n",
        "        smoothing = []\n",
        "        for i in range(len(predicts) - self.wide):\n",
        "            smoothing.append(sum(predicts[i:i + self.wide]) / self.wide)\n",
        "        return [smoothing[0]] * self.wide + smoothing\n",
        "\n",
        "\n",
        "    def _hysteresis(self, predicts):\n",
        "        hyst = []\n",
        "        if predicts[0] < 0.5:\n",
        "            hyst.append(0)\n",
        "        else:\n",
        "            hyst.append(1)\n",
        "        for i in range(1, len(predicts)):\n",
        "            if hyst[-1] == 0:\n",
        "                if predicts[i] > 0.9:\n",
        "                    hyst.append(1)\n",
        "                else:\n",
        "                    hyst.append(0)\n",
        "            else:\n",
        "                if predicts[i] < 0.1:\n",
        "                    hyst.append(0)\n",
        "                else:\n",
        "                    hyst.append(1)\n",
        "        return hyst\n",
        "\n",
        "\n",
        "    def _mount_filter(self, predicts):\n",
        "        accumulator = []\n",
        "        result = []\n",
        "\n",
        "        position = predicts[0]\n",
        "\n",
        "        for predict in predicts:\n",
        "            if predict != position:\n",
        "                if len(accumulator) < self.threshold:\n",
        "                    result += [predict] * len(accumulator)\n",
        "                else:\n",
        "                    result += accumulator\n",
        "                    position = predict\n",
        "                accumulator = [predict]\n",
        "            else:\n",
        "                accumulator.append(predict)\n",
        "        if accumulator:\n",
        "            result += accumulator\n",
        "        return result"
      ],
      "metadata": {
        "id": "17sGKrffc3Kq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pose_predict(cap, model):\n",
        "    _, image = cap.read()\n",
        "    try:\n",
        "        with mp.solutions.pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=0) as pose:\n",
        "            results = pose.process(image)\n",
        "        points = []\n",
        "        for i, point in enumerate(results.pose_world_landmarks.landmark):\n",
        "            if i in key_points:\n",
        "                points.append([point.x, point.y, point.z])\n",
        "        points = np.array(points).reshape(-1)\n",
        "        with torch.no_grad():\n",
        "            predict = torch.sigmoid(model(torch.FloatTensor(points))).cpu().detach().numpy()[0]\n",
        "    except:\n",
        "        predict = -1\n",
        "        points = np.zeros(27)\n",
        "    return predict, points, image"
      ],
      "metadata": {
        "id": "B13GhT1rhSEA"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_detector(predicts, start_delay=30):\n",
        "    cnt = 0\n",
        "    for predict in predicts:\n",
        "        if cnt >= start_delay:\n",
        "            return 1\n",
        "        if predict:\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1     \n",
        "    return 0"
      ],
      "metadata": {
        "id": "EmIpLYxlx20C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def farme_detector(predicts):\n",
        "    for i in range(2, len(predicts)):\n",
        "        if (predicts[i - 2] == 1) and (predicts[i - 1] == 0):\n",
        "            return 1\n",
        "    return 0"
      ],
      "metadata": {
        "id": "AJIC4qQRyTLa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frame_equalizer(predicts, points_list):\n",
        "    l = sum(predicts)\n",
        "    m = len(predicts) - l - 1\n",
        "    if m > l:\n",
        "       return points_list[len(points_list) - l * 2 - 1:]\n",
        "    return points_list"
      ],
      "metadata": {
        "id": "yuXGukysHoYC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gap_filler(sequence):\n",
        "    result = []\n",
        "    # find first nonzero frame\n",
        "    for i, frame in enumerate(sequence):\n",
        "        if (frame != np.zeros(27)).all():\n",
        "            result = [frame] * (i + 1)\n",
        "            start = len(result)\n",
        "            break\n",
        "    for frame in sequence[start:]:\n",
        "        if (frame != np.zeros(27)).all():\n",
        "            result.append(frame)\n",
        "        else:\n",
        "            result.append(result[-1])\n",
        "    return result"
      ],
      "metadata": {
        "id": "ee7STDHGN5c2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keyframes(sequence, N=16):\n",
        "    if len(sequence) >= N:\n",
        "        sequence = gap_filler(sequence)\n",
        "        idx = [((len(sequence) * (i + 1)) // N) - 1 for i in range(N)]\n",
        "        result = [frame for i, frame in enumerate(sequence) if i in idx]\n",
        "    else:\n",
        "        result = sequence + [sequence[-1]] * (N - len(sequence))\n",
        "    return result"
      ],
      "metadata": {
        "id": "hRcGBSx7B0v2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/ml/VID_20220822_162003_146.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(path)\n",
        "cleaner = Cleaner(wide=10, threshold=15)\n",
        "\n",
        "frames_list = []\n",
        "predicts = []\n",
        "cnt = 0\n",
        "cnt_list = []\n",
        "start = 0\n",
        "i_list = []\n",
        "predicts_src = []\n",
        "points_list = []\n",
        "for i in tqdm(range(int(cv2.VideoCapture(path).get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "    predict, points = get_pose_predict(cap, model)\n",
        "    predicts.append(predict)\n",
        "    predicts_src.append(predict)\n",
        "    points_list.append(points)\n",
        "    if len(predicts) >= 30:\n",
        "        # smoothing for all data\n",
        "        predicts_clean = cleaner.clean(predicts_src)[-len(predicts):]\n",
        "        if start:\n",
        "            if farme_detector(predicts_clean):\n",
        "                frame = frame_equalizer(predicts_clean, points_list)\n",
        "                frames_list.append(get_keyframes(frame))\n",
        "                predicts = []\n",
        "                points_list = []\n",
        "                cnt += 1\n",
        "        else:\n",
        "            if start_detector(predicts_clean, ):\n",
        "                predicts = []\n",
        "                points_list = []\n",
        "                start = 1\n",
        "    # video stream reconstruction\n",
        "    cnt_list.append(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbFAhqJAvJhq",
        "outputId": "79126d1b-b8e8-42b7-9821-4afa260cec06"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1683/1683 [05:03<00:00,  5.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(frames_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXW6aHOdh0dz",
        "outputId": "167b78f5-cbf7-4087-e00b-dc689f739e36"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generate data for movement classifier"
      ],
      "metadata": {
        "id": "Rp3FYo4-e87B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/ml/correct100.p'"
      ],
      "metadata": {
        "id": "u4J7GSbSiHsq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path, 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "TnZOW7KViYGb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = Cleaner(wide=10, threshold=15)"
      ],
      "metadata": {
        "id": "ajbeiwB0zKIB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(data, cleaner):\n",
        "    frames_list = []\n",
        "    predicts = []\n",
        "    start = 0\n",
        "    i_list = []\n",
        "    predicts_src = []\n",
        "    points_list = []\n",
        "\n",
        "    for points in tqdm(data):\n",
        "        with torch.no_grad():\n",
        "            predict = torch.sigmoid(model(torch.FloatTensor(points))).cpu().detach().numpy()[0]\n",
        "        predicts.append(predict)\n",
        "        predicts_src.append(predict)\n",
        "        points_list.append(points)\n",
        "        if len(predicts) >= 30:\n",
        "            # smoothing for all data\n",
        "            predicts_clean = cleaner.clean(predicts_src)[-len(predicts):]\n",
        "            if start:\n",
        "                if farme_detector(predicts_clean):\n",
        "                    frame = frame_equalizer(predicts_clean, points_list)\n",
        "                    frames_list.append(get_keyframes(frame))\n",
        "                    predicts = []\n",
        "                    points_list = []\n",
        "            else:\n",
        "                if start_detector(predicts_clean, start_delay=30):\n",
        "                    predicts = []\n",
        "                    points_list = []\n",
        "                    start = 1\n",
        "    return frames_list"
      ],
      "metadata": {
        "id": "U7ycvTEJybTR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for path in paths_list:\n",
        "    name = path.split('/')[-1][:-4]\n",
        "    with open('/content/drive/MyDrive/ml/' + name + '.p', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    data_list.append(get_data(data, cleaner))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoy95m8Npgow",
        "outputId": "d3f1f88f-771e-4185-f2bc-5806de986730"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7076/7076 [01:49<00:00, 64.72it/s]\n",
            "100%|██████████| 6931/6931 [01:43<00:00, 67.09it/s]\n",
            "100%|██████████| 5898/5898 [02:14<00:00, 43.84it/s]\n",
            "100%|██████████| 6962/6962 [01:39<00:00, 69.70it/s]\n",
            "100%|██████████| 7292/7292 [01:57<00:00, 61.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ml/squat_dataset.p', 'wb') as f:\n",
        "    pickle.dump(data_list, f)"
      ],
      "metadata": {
        "id": "xvUiRAZHDWev"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ml/squat_dataset.p', 'rb') as f:\n",
        "    data_list = pickle.load(f)\n",
        "\n",
        "data_list.pop(2);"
      ],
      "metadata": {
        "id": "OCuIIP3pilrJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create datset 4 multiclass classificaion"
      ],
      "metadata": {
        "id": "LOGLKIjKC-s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points_list = []\n",
        "labels_list = []\n",
        "for i, data in enumerate(data_list):\n",
        "    for sequence in data:\n",
        "        points_list.append(np.asarray(sequence))\n",
        "        labels_list.append(i)"
      ],
      "metadata": {
        "id": "KRArAru0qgT0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['points'] = points_list\n",
        "df['label'] = labels_list"
      ],
      "metadata": {
        "id": "8Wh4oavKuyXC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "E8fe0BeCvIBg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "PQrz14kKvZ7H"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, points, labels):\n",
        "        self.points = points\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.points[index].reshape(-1), torch.FloatTensor(self.labels[index])\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.points)"
      ],
      "metadata": {
        "id": "A-QrhF9Wv85-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(torch.FloatTensor(list(train['points'])), torch.FloatTensor(list(train['label'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAFpxVSqxYHo",
        "outputId": "8a9d6a1d-b275-4fa9-f4e4-773428518f6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(torch.FloatTensor(list(test['points'])), torch.FloatTensor(list(test['label'])))"
      ],
      "metadata": {
        "id": "67h0N8IqEQrf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "GD7-k_NZx-m8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimleNetwork(432, 300, 4)"
      ],
      "metadata": {
        "id": "1QB85fp0ydgE"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "model.apply(init_weights);"
      ],
      "metadata": {
        "id": "3Pi6s7Hd0IX7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device);"
      ],
      "metadata": {
        "id": "gE-_SHG-0NoA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "NeATn1Ky0P19"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Wt8R_K8Y0Adi"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmTO3fy3xhO9",
        "outputId": "65b2baaa-fad5-4896-a1f6-533f6b942f8d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, test_dataset):\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, label in test_dataset:\n",
        "            prediction = model(X)\n",
        "            prediction = prediction.max(0, keepdim=True)[1]\n",
        "            prediction = prediction.reshape(1, -1).cpu().detach().numpy()[0]\n",
        "            predictions.append(prediction)\n",
        "            labels.append(label)\n",
        "    return predictions, labels"
      ],
      "metadata": {
        "id": "ROKBu32x3zGi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for data in tqdm(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        try:\n",
        "            # outputs = torch.sigmoid(model(inputs))\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    predictions, labels = eval(model, test_dataset)\n",
        "    score = f1_score(labels, predictions, average='macro')\n",
        "    if score > best_score:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_score = score\n",
        "        print(epoch, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN9QmZvo1tFR",
        "outputId": "0c09bda8-0e89-4e7b-a3d9-c8fb3345603a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:01<00:00, 114.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6724129605485538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:01<00:00, 127.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.9462811107996139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:01<00:00, 128.70it/s]\n",
            "100%|██████████| 163/163 [00:01<00:00, 127.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 0.9855252274607114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:01<00:00, 94.91it/s]\n",
            "100%|██████████| 163/163 [00:01<00:00, 82.12it/s]\n",
            "100%|██████████| 163/163 [00:01<00:00, 85.40it/s]\n",
            "100%|██████████| 163/163 [00:01<00:00, 84.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:02<00:00, 79.65it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 78.22it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 75.96it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 74.22it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 75.82it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 72.15it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 72.03it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 72.17it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 73.07it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 72.60it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 74.18it/s]\n",
            "100%|██████████| 163/163 [00:02<00:00, 72.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save NN\n",
        "path = '/content/drive/MyDrive/ml/model_squat_classifier_v0.pt'\n",
        "torch.save(best_model.state_dict(), path)"
      ],
      "metadata": {
        "id": "fh_x9imxx9hr"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = SimleNetwork(432, 300, 4)"
      ],
      "metadata": {
        "id": "T3NzzSOKyawj"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.load_state_dict(torch.load(path));"
      ],
      "metadata": {
        "id": "LXulzxzIym9U"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels = eval(test_model, test_dataset)"
      ],
      "metadata": {
        "id": "OwSnSQvCygXa"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(labels, predictions, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soq3Bc2FyvA-",
        "outputId": "c92f223b-4250-418f-9a67-73b56f110235"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test on video"
      ],
      "metadata": {
        "id": "MYylc29eyzyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_frame = SimleNetwork(27, 200, 1)"
      ],
      "metadata": {
        "id": "LlKQymjQDEOQ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_frame.load_state_dict(torch.load('/content/drive/MyDrive/ml/model_mov_v0.pt'));"
      ],
      "metadata": {
        "id": "3Aoe-EO1DKiW"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cls = SimleNetwork(432, 300, 4)"
      ],
      "metadata": {
        "id": "sKNiVNYzDRVf"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cls.load_state_dict(torch.load('/content/drive/MyDrive/ml/model_squat_classifier_v0.pt'));"
      ],
      "metadata": {
        "id": "M4mprfLmDV3V"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_squat_kind(model, sequence):\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "            prediction = model(sequence)\n",
        "            prediction = prediction.max(0, keepdim=True)[1]\n",
        "            prediction = prediction.reshape(1, -1).cpu().detach().numpy()[0]\n",
        "    return int(prediction)"
      ],
      "metadata": {
        "id": "uw8DwF2cG4aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_predict(image, text):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    bottomLeftCornerOfText = (10, 1200)\n",
        "    fontScale = 2\n",
        "    fontColor = (255,0,0)\n",
        "    thickness = 2\n",
        "    lineType = 2\n",
        "\n",
        "    cv2.putText(\n",
        "        image,\n",
        "        text, \n",
        "        bottomLeftCornerOfText, \n",
        "        font, \n",
        "        fontScale,\n",
        "        fontColor,\n",
        "        thickness,\n",
        "        lineType\n",
        "        )"
      ],
      "metadata": {
        "id": "uTEz1DvnK3rQ"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_dict = {\n",
        "    0: 'ok',\n",
        "    1: 'back',\n",
        "    2: 'knees',\n",
        "    3: 'uneven',\n",
        "    -1: '...'\n",
        "}"
      ],
      "metadata": {
        "id": "JSpxP3iMLUOn"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/ml/VID_20220831_154203_059.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(path)\n",
        "cleaner = Cleaner(wide=10, threshold=15)\n",
        "\n",
        "predicts = []\n",
        "cnt = 0\n",
        "start = 0\n",
        "predicts_src = []\n",
        "points_list = []\n",
        "kind = -1\n",
        "images = []\n",
        "for i in tqdm(range(int(cv2.VideoCapture(path).get(cv2.CAP_PROP_FRAME_COUNT)))):\n",
        "    predict, points, image = get_pose_predict(cap, model_frame)\n",
        "    predicts.append(predict)\n",
        "    predicts_src.append(predict)\n",
        "    points_list.append(points)\n",
        "    if len(predicts) >= 30:\n",
        "        # smoothing for all data\n",
        "        predicts_clean = cleaner.clean(predicts_src)[-len(predicts):]\n",
        "        if start:\n",
        "            if farme_detector(predicts_clean):\n",
        "                frame = frame_equalizer(predicts_clean, points_list)\n",
        "                frame = get_keyframes(frame)\n",
        "                kind = get_squat_kind(model_cls, torch.FloatTensor(np.asarray(frame)).reshape(-1))\n",
        "                predicts = []\n",
        "                points_list = []\n",
        "                cnt += 1\n",
        "        else:\n",
        "            if start_detector(predicts_clean, start_delay=30):\n",
        "                predicts = []\n",
        "                points_list = []\n",
        "                start = 1\n",
        "    # video stream reconstruction\n",
        "    # cnt, kind\n",
        "    text = str(cnt) + ': ' + squad_dict[kind]\n",
        "    add_predict(image, text)\n",
        "    images.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxI7vbet9SUL",
        "outputId": "e8e10e85-316e-4d9a-f2ab-d66491794a17"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1683/1683 [05:18<00:00,  5.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "width = images[0].shape[1]\n",
        "height = images[0].shape[0]"
      ],
      "metadata": {
        "id": "SPdBQlxSNtvF"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "video = cv2.VideoWriter('/content/drive/MyDrive/ml/ml_pipeline_test_v0.mp4',fourcc,30,(width,height))"
      ],
      "metadata": {
        "id": "FYIvRjgQNuj7"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in tqdm(images):\n",
        "    video.write(image)\n",
        "\n",
        "video.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ots7zs8kNumS",
        "outputId": "a60d3697-f459-4729-f8dc-3fded5e6cdbf"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1683/1683 [00:12<00:00, 134.07it/s]\n"
          ]
        }
      ]
    }
  ]
}